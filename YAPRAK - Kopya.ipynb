{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18648,"databundleVersionId":1026645,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.620391Z","iopub.status.idle":"2025-09-19T21:30:21.620818Z","shell.execute_reply.started":"2025-09-19T21:30:21.620592Z","shell.execute_reply":"2025-09-19T21:30:21.620611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plant Pathology 2020 - Yaprak Hastalıkları Sınıflandırma\nProje: Kaggle Deep Learning Bootcamp için hazırlanmıştır.\nVeri: Plant Pathology 2020 (Kaggle competition)\nAmaç: Yaprak resimlerini 4 sınıfa ayıran bir CNN + Transfer Learning modeli oluşturmak.\n","metadata":{}},{"cell_type":"code","source":"# Hücre 2 - Kütüphaneler\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.622214Z","iopub.status.idle":"2025-09-19T21:30:21.622626Z","shell.execute_reply.started":"2025-09-19T21:30:21.622429Z","shell.execute_reply":"2025-09-19T21:30:21.622446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hücre 3 - Veri dosyasını kontrol et\n# Eğer dataset'i \"Add data\" ile eklediyseniz path şu şekilde olacaktır; aksi halde sağ paneldeki dataset eklendikten sonra path'ı kopyalayın.\nbase_path = \"/kaggle/input/plant-pathology-2020-fgvc7\"   # Eğer farklıysa burayı sağ paneldeki path ile değiştirin\n\nprint(\"Dosyalar:\", os.listdir(base_path)[:20])\ncsv_file = os.path.join(base_path, \"train.csv\")\ndf = pd.read_csv(csv_file)\nprint(df.shape)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.624248Z","iopub.status.idle":"2025-09-19T21:30:21.624641Z","shell.execute_reply.started":"2025-09-19T21:30:21.624454Z","shell.execute_reply":"2025-09-19T21:30:21.624471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hücre 4 - Label sütunu yoksa oluştur (competition CSV'si genelde one-hot formatında 'healthy','multiple_diseases','rust','scab' kolonlarıyla gelir)\nif 'label' not in df.columns:\n    possible = {'healthy','multiple_diseases','rust','scab'}\n    if possible.issubset(set(df.columns)):\n        def make_label(row):\n            for c in ['healthy','multiple_diseases','rust','scab']:\n                if row[c] == 1:\n                    return c\n        df['label'] = df.apply(make_label, axis=1)\n    elif 'labels' in df.columns or 'category' in df.columns:\n        # farklı format varsa:\n        df.rename(columns={'labels':'label','category':'label'}, inplace=True)\n\ndf['image_id'] = df['image_id'].astype(str) + \".jpg\"\nprint(\"Sınıf dağılımı:\")\ndisplay(df['label'].value_counts())\n\n# Örnek görseller\nsample = df.sample(6, random_state=42)\nplt.figure(figsize=(12,6))\nfor i, row in enumerate(sample.itertuples()):\n    plt.subplot(2,3,i+1)\n    img = mpimg.imread(os.path.join(base_path, \"images\", row.image_id))\n    plt.imshow(img)\n    plt.title(row.label)\n    plt.axis('off')\nplt.tight_layout()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.626228Z","iopub.status.idle":"2025-09-19T21:30:21.626619Z","shell.execute_reply.started":"2025-09-19T21:30:21.626432Z","shell.execute_reply":"2025-09-19T21:30:21.626449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hücre 5 - Split ve ImageDataGenerator\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\nprint(train_df.shape, val_df.shape)\n\n# Augmentation & generator\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=25,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df, directory=os.path.join(base_path, \"images\"),\n    x_col=\"image_id\", y_col=\"label\",\n    target_size=(224,224), class_mode=\"categorical\", batch_size=32, shuffle=True\n)\n\nval_gen = val_datagen.flow_from_dataframe(\n    val_df, directory=os.path.join(base_path, \"images\"),\n    x_col=\"image_id\", y_col=\"label\",\n    target_size=(224,224), class_mode=\"categorical\", batch_size=32, shuffle=False\n)\n\nclass_indices = train_gen.class_indices\nprint(\"Sınıf indeksi:\", class_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.629065Z","iopub.status.idle":"2025-09-19T21:30:21.629475Z","shell.execute_reply.started":"2025-09-19T21:30:21.629268Z","shell.execute_reply":"2025-09-19T21:30:21.629296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nimport tensorflow as tf\n\ninputs = tf.keras.Input(shape=(224,224,3))\nx = layers.Conv2D(32, (3,3), activation='relu')(inputs)\nx = layers.MaxPooling2D(2,2)(x)\n\nx = layers.Conv2D(64, (3,3), activation='relu')(x)\nx = layers.MaxPooling2D(2,2)(x)\n\nx = layers.Conv2D(128, (3,3), activation='relu')(x)\nx = layers.MaxPooling2D(2,2)(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(128, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(len(class_indices), activation='softmax')(x)\n\nmodel = models.Model(inputs, outputs)   # ✅ Functional Model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.630803Z","iopub.status.idle":"2025-09-19T21:30:21.631346Z","shell.execute_reply.started":"2025-09-19T21:30:21.631168Z","shell.execute_reply":"2025-09-19T21:30:21.631185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5   # başlangıç için 5 epoch ideal\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.633567Z","iopub.status.idle":"2025-09-19T21:30:21.633965Z","shell.execute_reply.started":"2025-09-19T21:30:21.633814Z","shell.execute_reply":"2025-09-19T21:30:21.633830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hücre 8 - Grafikleri çiz\nplt.figure(); plt.plot(history.history['accuracy'], label='train_acc'); plt.plot(history.history['val_accuracy'], label='val_acc'); plt.legend(); plt.grid();\nplt.figure(); plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.grid();\n\n# Confusion matrix\nval_preds = model.predict(val_gen)\ny_true = val_gen.classes\ny_pred = np.argmax(val_preds, axis=1)\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=list(class_indices.keys()), yticklabels=list(class_indices.keys()))\nplt.xlabel('Tahmin'); plt.ylabel('Gerçek'); plt.title('Confusion Matrix')\nplt.show()\n\nprint(classification_report(y_true, y_pred, target_names=list(class_indices.keys()), zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.635039Z","iopub.status.idle":"2025-09-19T21:30:21.635429Z","shell.execute_reply.started":"2025-09-19T21:30:21.635211Z","shell.execute_reply":"2025-09-19T21:30:21.635230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\n\ndef make_gradcam_heatmap(img_array, model):\n    # Son Conv2D katmanını bul\n    conv_layer = None\n    for layer in reversed(model.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            conv_layer = layer\n            break\n\n    # Grad-CAM modeli: son conv + output\n    grad_model = tf.keras.models.Model(\n        inputs=model.input,\n        outputs=[conv_layer.output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        pred_index = tf.argmax(predictions[0])\n        pred_output = predictions[:, pred_index]\n\n    grads = tape.gradient(pred_output, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n    return heatmap.numpy(), conv_layer.name\n\n\n# ✅ ÖRNEK kullanım\nimg_path = os.path.join(base_path, \"images\", val_df.sample(1).iloc[0]['image_id'])\nimg = tf.keras.preprocessing.image.load_img(img_path, target_size=(224,224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)/255.0\nimg_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n\nheatmap, used_layer = make_gradcam_heatmap(img_array, model)\nprint(\"Kullanılan son conv layer:\", used_layer)\n\n# Orijinal resim\nimg_orig = cv2.imread(img_path)\nimg_orig = cv2.resize(img_orig, (224,224))\n\n# Heatmap üstüne bindir\nheatmap = cv2.resize(heatmap, (224,224))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\nsuperimposed_img = heatmap * 0.4 + img_orig\n\n# ✅ Çiz\nplt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nplt.imshow(cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB))\nplt.title('Original'); plt.axis('off')\n\nplt.subplot(1,2,2)\nplt.imshow(cv2.cvtColor(superimposed_img.astype(np.uint8), cv2.COLOR_BGR2RGB))\nplt.title('Grad-CAM'); plt.axis('off')\n\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.636842Z","iopub.status.idle":"2025-09-19T21:30:21.637161Z","shell.execute_reply.started":"2025-09-19T21:30:21.637003Z","shell.execute_reply":"2025-09-19T21:30:21.637018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modeli kaydet\nmodel.save(\"plant_disease_model.h5\")\nprint(\"✅ Model başarıyla kaydedildi: plant_disease_model.h5\")\n\n# Eğitim eğrilerini çizdir\nplt.figure(figsize=(8,4))\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T21:30:21.638535Z","iopub.status.idle":"2025-09-19T21:30:21.638851Z","shell.execute_reply.started":"2025-09-19T21:30:21.638680Z","shell.execute_reply":"2025-09-19T21:30:21.638691Z"}},"outputs":[],"execution_count":null}]}